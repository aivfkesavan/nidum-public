[
  {
    "name": "Llama 3.1 8B",
    "size": "4.70 GB",
    "id": "llama3.1",
    "file_name": "llama3.1_8b_q4.gguf",
    "hf_link": "hf:mradermacher/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct.Q4_K_M.gguf",
    "category": "General Purpose - Medium",
    "description": "Llama 3.1 8B Q4 is the latest state-of-the-art model from Meta (Needs 8GB RAM)"
  },
  {
    "name": "Gemma 2 9B",
    "size": "3.43 GB",
    "id": "gemma2:9b",
    "file_name": "gemma_2_9b_q2.gguf",
    "hf_link": "hf:bartowski/gemma-2-9b-it-GGUF/gemma-2-9b-it-IQ2_M.gguf",
    "category": "General Purpose - Small",
    "description": "Gemma 2 2B Q4 is a small but high-performing and efficient model by Google (Needs 4GB RAM)"
  },
  {
    "name": "Llama 3.2 1B",
    "size": "345 MB",
    "id": "llama3.2-1b",
    "file_name": "llama3.2_1b_q1.gguf",
    "hf_link": "hf:mradermacher/meta-llama-Llama-3.2-1B-Instruct-qlora-malaysian-16k-i1-GGUF/meta-llama-Llama-3.2-1B-Instruct-qlora-malaysian-16k.i1-IQ1_S.gguf",
    "category": "General Purpose - Small",
    "description": "Gemma 2 2B Q4 is a small but high-performing and efficient model by Google (Needs 4GB RAM)"
  }
]
