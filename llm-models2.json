[
  {
    "name": "Llama 3.1 8B",
    "size": "4.70 GB",
    "id": "llama3.1",
    "category": "General Purpose - Medium",
    "description": "Llama 3.1 is the latest state-of-the-art model from Meta (Needs 8GB RAM)"
  },
  {
    "name": "Gemma 2 2B",
    "size": "1.60 GB",
    "id": "gemma2:9b",
    "category": "General Purpose - Small",
    "description": "Gemma 2 2B is a small but high-performing and efficient model by Google (Needs 4GB RAM)"
  },
  {
    "name": "DeepSeek Coder V2 16B",
    "size": "8.90 GB",
    "id": "deepseek-coder-v2",
    "category": "Coding Tasks - Medium",
    "description": "An open-source Mixture-of-Experts code language model for in code-specific tasks (Needs 9GB RAM)"
  },
  {
    "name": "Dolphin llama3 8B",
    "size": "4.7GB GB",
    "id": "dolphin-llama3",
    "category": "Uncensored - Large",
    "description": "Uncensored fine-tuned models based on the Mixtral models (Needs 8GB RAM)"
  },
  {
    "name": "Phi 3.5 3B",
    "size": "2.20 GB",
    "id": "phi3.5",
    "category": "General Purpose - Small",
    "description": "A lightweight AI model with 3.8B parameters with performance above its weight class (Needs 4GB RAM)"
  },
  {
    "name": "LLAVA 7B (Vision)",
    "size": "4.70 GB",
    "id": "llava:7b",
    "category": "General Purpose - Large",
    "description": "A AI model with image processing capabilities (Needs 8GB RAM)"
  }
]
